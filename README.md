# Model-based-RL-and-Contextual-RL
We implement, propose and test different model based RL algorithm 

## Research Schedule

### Summer 2020 (Jun - Aug)
Numerical experiment for **model-based Reinforcement Learning**. The detailed code and report is summerized in the folder "**/RL**". In this part we implemtent, test and compare two main types of model-based RL algorithm: Upper Confidence Bound (UCB) and Posterior Sampling (PS, Thompson Sampling). We compare several versions of PSRL(Agrawal et al., 2017) with the benchmark UCRL2(Jaksch et al., 2010) to see how Thompson Sampling may bring the improvement in RL problem. 

### Fall 2020 (Sep - Dec)
Empirically test new proposed Posterior Sampling algorithm for **model-based Contextual Reinforcement Learning**. The detailed code and report is summerized in the folder "**/Contextual RL**". In this part we plan to design, implement and test the new contextual RL algorithm. The Contexual RL is designed for large statet space MDP problem like many real world problem: assortment recommendation, Open AI game...
